---
title: Advanced Usage
description: Advanced patterns and techniques for using the Store adapter. Learn about error handling, performance optimization, monitoring, and production best practices.
---

## Overview

This guide covers advanced patterns and techniques for using the Store adapter in production environments. Learn about error handling, performance optimization, monitoring, and architectural patterns that help you build robust, scalable applications using the Store adapter effectively.

Advanced patterns go beyond basic caching and Pub/Sub operations to address real-world challenges like fault tolerance, performance optimization, and architectural design. Understanding these patterns helps you build production-ready applications that handle failures gracefully, perform well under load, and scale effectively.

---

## Error Handling Strategies

Robust error handling ensures your application continues functioning even when the Store adapter encounters issues. These strategies help you build resilient systems that gracefully handle failures, retry transient errors, and fall back to alternative data sources when caching fails.

Error handling is critical in production environments where Redis might be temporarily unavailable or network issues might interrupt operations. These strategies ensure your application remains functional and provides a good user experience even when caching fails.

<Accordions>
  <Accordion title="Circuit Breaker Pattern">
    Implement a circuit breaker to prevent cascading failures when Redis is unavailable. Circuit breakers stop attempting operations after repeated failures, allowing the system to recover gracefully. This pattern prevents a failing Redis instance from overwhelming your application with retry attempts.
    
    ```typescript
    class StoreCircuitBreaker {
      private failures = 0;
      private lastFailureTime = 0;
      private state: 'closed' | 'open' | 'half-open' = 'closed';
      
      constructor(
        private threshold = 5,
        private timeout = 60000 // 1 minute
      ) {}
      
      async execute<T>(
        operation: () => Promise<T>,
        fallback?: () => Promise<T>
      ): Promise<T> {
        if (this.state === 'open') {
          if (Date.now() - this.lastFailureTime > this.timeout) {
            this.state = 'half-open';
          } else {
            if (fallback) return fallback();
            throw new Error('Circuit breaker is open');
          }
        }
        
        try {
          const result = await operation();
          this.onSuccess();
          return result;
        } catch (error) {
          this.onFailure();
          if (fallback) return fallback();
          throw error;
        }
      }
      
      private onSuccess() {
        this.failures = 0;
        this.state = 'closed';
      }
      
      private onFailure() {
        this.failures++;
        this.lastFailureTime = Date.now();
        
        if (this.failures >= this.threshold) {
          this.state = 'open';
        }
      }
    }

    // Usage
    const circuitBreaker = new StoreCircuitBreaker();

    const getCached = async (key: string, context: AppContext) => {
      return circuitBreaker.execute(
        () => igniter.store.get(key),
        () => fetchFromDatabase(key) // Fallback
      );
    };
    ```
    
    Circuit breakers prevent cascading failures by stopping operations after repeated failures. They automatically recover after a timeout, allowing your system to resume normal operation once Redis is available again.
  </Accordion>
  
  <Accordion title="Retry with Exponential Backoff">
    Implement retry logic for transient failures using exponential backoff. Exponential backoff gradually increases wait times between retries, preventing overwhelming Redis with rapid retry attempts while still allowing operations to succeed once transient issues resolve.
    
    ```typescript
    const retryWithBackoff = async <T>(
      operation: () => Promise<T>,
      maxRetries = 3,
      baseDelay = 1000
    ): Promise<T> => {
      let lastError: Error;
      
      for (let attempt = 0; attempt <= maxRetries; attempt++) {
        try {
          return await operation();
        } catch (error) {
          lastError = error as Error;
          
          if (attempt < maxRetries) {
            const delay = baseDelay * Math.pow(2, attempt);
            await new Promise(resolve => setTimeout(resolve, delay));
          }
        }
      }
      
      throw lastError!;
    };

    // Usage
    const getWithRetry = async (key: string, context: AppContext) => {
      return retryWithBackoff(
        () => igniter.store.get(key),
        3,
        1000
      );
    };
    ```
    
    Retry with exponential backoff handles transient failures gracefully. Increasing delays between retries prevent overwhelming Redis while allowing operations to succeed once transient issues resolve.
  </Accordion>
  
  <Accordion title="Fallback Strategies">
    Implement fallback strategies when cache fails to ensure your application continues functioning. Fallback strategies allow your application to degrade gracefully by falling back to alternative data sources when caching operations fail.
    
    ```typescript
    const getWithFallback = async <T>(
      key: string,
      fetchFn: () => Promise<T>,
      context: AppContext
    ): Promise<T> => {
      try {
        // Try cache first
        const cached = await igniter.store.get<T>(key);
        if (cached) {
          return cached;
        }
        
        // Fetch from source
        const data = await fetchFn();
        
        // Cache result
        await igniter.store.set(key, data, { ttl: 3600 });
        
        return data;
      } catch (cacheError) {
        // Cache failed, fall back to source
        context.logger.warn('Cache failed, using fallback', { error: cacheError });
        return fetchFn();
      }
    };
    ```
    
    Fallback strategies ensure your application continues functioning when caching fails. Always have fallback strategies that allow your application to degrade gracefully and continue serving users even when Redis is unavailable.
  </Accordion>
</Accordions>

---

## Performance Optimization

Optimizing Store adapter performance involves understanding connection pooling, pipeline operations, and compression techniques. These optimizations help you build high-performance applications that scale well under load and efficiently use Redis resources.

Performance optimization is essential for production applications where every millisecond counts. Understanding these techniques helps you build fast, efficient applications that make optimal use of Redis resources.

<Accordions>
  <Accordion title="Connection Pooling">
    Optimize Redis connection usage with connection pooling. Connection pooling manages multiple Redis connections efficiently, reducing connection overhead and improving throughput. Proper connection pooling ensures your application performs well under high load.
    
    ```typescript
    import { Redis, Cluster } from 'ioredis';

    // Single instance with connection pool
    const redis = new Redis({
      host: process.env.REDIS_HOST,
      port: parseInt(process.env.REDIS_PORT || '6379'),
      maxRetriesPerRequest: 3,
      enableReadyCheck: true,
      enableOfflineQueue: true,
      
      // Connection pool settings
      connectTimeout: 10000,
      lazyConnect: false,
      
      // Retry strategy
      retryStrategy: (times) => {
        if (times > 3) return null;
        return Math.min(times * 50, 2000);
      },
    });

    export const store = createRedisStoreAdapter(redis);
    ```
    
    Connection pooling improves performance by managing connections efficiently. Configure connection pools based on your application's concurrency needs and Redis capacity.
  </Accordion>
  
  <Accordion title="Pipeline Operations">
    Batch multiple operations using Redis pipelines to reduce round trips. Pipelines send multiple commands to Redis in a single round trip, dramatically improving performance when performing many operations.
    
    ```typescript
    // Note: The adapter doesn't expose pipelines directly,
    // but you can access the client for advanced operations
    const batchGet = async (
      keys: string[],
      context: AppContext
    ): Promise<(any | null)[]> => {
      const redis = igniter.store.client as Redis;
      const pipeline = redis.pipeline();
      
      keys.forEach(key => pipeline.get(key));
      
      const results = await pipeline.exec();
      
      return results!.map(([err, result]) => {
        if (err) return null;
        try {
          return JSON.parse(result as string);
        } catch {
          return result;
        }
      });
    };
    ```
    
    Pipeline operations reduce latency by batching multiple commands into a single round trip. Use pipelines when performing many operations simultaneously to improve performance.
  </Accordion>
  
  <Accordion title="Compression">
    Compress large values before storing to reduce memory usage and improve performance. Compression is particularly useful for large objects, strings, or arrays that consume significant memory when cached.
    
    ```typescript
    import { gzip, gunzip } from 'zlib';
    import { promisify } from 'util';

    const gzipAsync = promisify(gzip);
    const gunzipAsync = promisify(gunzip);

    const setCompressed = async (
      key: string,
      value: any,
      options?: { ttl?: number },
      context: AppContext
    ) => {
      const serialized = JSON.stringify(value);
      const compressed = await gzipAsync(serialized);
      
      await igniter.store.set(key, compressed.toString('base64'), options);
    };

    const getCompressed = async <T>(
      key: string,
      context: AppContext
    ): Promise<T | null> => {
      const compressed = await igniter.store.get<string>(key);
      if (!compressed) return null;
      
      const buffer = Buffer.from(compressed, 'base64');
      const decompressed = await gunzipAsync(buffer);
      
      return JSON.parse(decompressed.toString()) as T;
    };
    ```
    
    Compression reduces memory usage for large cached values, improving Redis performance and reducing costs. Use compression for large objects that benefit from size reduction.
  </Accordion>
</Accordions>

---

## Monitoring and Observability

Monitoring and observability help you understand how your Store adapter is performing in production. Collecting metrics, implementing health checks, and tracking performance characteristics helps you identify issues early and optimize your Store usage effectively.

Good monitoring provides visibility into cache performance, error rates, and latency. This helps you optimize cache usage, identify bottlenecks, and ensure your caching strategy is working effectively.

<Accordions>
  <Accordion title="Metrics Collection">
    Collect metrics for monitoring cache performance, hit rates, and error rates. Metrics help you understand how your cache is performing and identify optimization opportunities. Track cache hits, misses, errors, and latency to optimize your caching strategy.
    
    ```typescript
    class StoreMetrics {
      private cacheHits = 0;
      private cacheMisses = 0;
      private errors = 0;
      
      recordHit() {
        this.cacheHits++;
      }
      
      recordMiss() {
        this.cacheMisses++;
      }
      
      recordError() {
        this.errors++;
      }
      
      getStats() {
        const total = this.cacheHits + this.cacheMisses;
        const hitRate = total > 0 ? (this.cacheHits / total) * 100 : 0;
        
        return {
          hits: this.cacheHits,
          misses: this.cacheMisses,
          errors: this.errors,
          hitRate: `${hitRate.toFixed(2)}%`,
        };
      }
    }

    // Usage
    const metrics = new StoreMetrics();

    const getWithMetrics = async <T>(
      key: string,
      context: AppContext
    ): Promise<T | null> => {
      try {
        const value = await igniter.store.get<T>(key);
        
        if (value) {
          metrics.recordHit();
        } else {
          metrics.recordMiss();
        }
        
        return value;
      } catch (error) {
        metrics.recordError();
        throw error;
      }
    };
    ```
    
    Metrics collection helps you understand cache performance and identify optimization opportunities. Track hit rates, error rates, and latency to optimize your caching strategy.
  </Accordion>
  
  <Accordion title="Health Checks">
    Implement health checks for monitoring Redis connectivity and performance. Health checks help you detect Redis issues early and ensure your application remains healthy. They're essential for production monitoring and alerting systems.
    
    ```typescript
    const checkStoreHealth = async (
      context: AppContext
    ): Promise<{ healthy: boolean; latency?: number; error?: string }> => {
      const start = Date.now();
      
      try {
        // Simple ping operation
        await igniter.store.has('health:check');
        
        const latency = Date.now() - start;
        
        return {
          healthy: true,
          latency,
        };
      } catch (error) {
        return {
          healthy: false,
          error: (error as Error).message,
        };
      }
    };

    // Health check endpoint
    export const healthController = igniter.controller({
      name: 'Health',
      description: 'Monitor application health and service connectivity',
      path: '/health',
      actions: {
        check: igniter.query({
          name: 'Health Check',
          description: 'Check the health status of all services including Redis',
          path: '/',
          handler: async ({ context, response }) => {
            const storeHealth = await checkStoreHealth(context);
            
            return response.success({
              status: storeHealth.healthy ? 'healthy' : 'unhealthy',
              store: storeHealth,
            });
          },
        }),
      },
    });
    ```
    
    Health checks enable proactive monitoring and alerting. They help you detect Redis issues before they impact users and ensure your application remains healthy.
  </Accordion>
</Accordions>

---

## Architectural Patterns

Architectural patterns help you organize Store adapter usage effectively in your application. These patterns demonstrate how to implement repository patterns, combine caching strategies, and integrate event sourcing with caching. Understanding these patterns helps you build maintainable, scalable applications.

Good architectural patterns make your code more maintainable and easier to understand. They provide proven solutions to common problems and help you build robust applications that scale well.

<Accordions>
  <Accordion title="Repository Pattern with Caching">
    Implement a repository pattern with automatic caching to simplify data access. This pattern encapsulates caching logic within repositories, making it easy to add caching to existing code without modifying business logic.
    
    ```typescript
    class CachedRepository<T> {
      constructor(
        private store: IgniterStoreAdapter,
        private fetchFn: (id: string) => Promise<T>,
        private ttl = 3600
      ) {}
      
      async findById(id: string): Promise<T | null> {
        const cacheKey = `${this.getEntityName()}:${id}`;
        
        // Try cache first
        const cached = await this.store.get<T>(cacheKey);
        if (cached) {
          return cached;
        }
        
        // Fetch from source
        const entity = await this.fetchFn(id);
        if (!entity) {
          return null;
        }
      
        // Cache result
        await this.store.set(cacheKey, entity, { ttl: this.ttl });
        
        return entity;
      }
      
      async invalidate(id: string): Promise<void> {
        const cacheKey = `${this.getEntityName()}:${id}`;
        await this.store.delete(cacheKey);
      }
      
      private getEntityName(): string {
        return this.constructor.name.toLowerCase().replace('repository', '');
      }
    }

    // Usage
    class UserRepository extends CachedRepository<User> {
      constructor(store: IgniterStoreAdapter, private db: Database) {
        super(store, (id) => db.user.findUnique({ where: { id } }), 3600);
      }
    }
    ```
    
    Repository pattern with caching simplifies data access by encapsulating caching logic. This pattern makes it easy to add caching to existing code without modifying business logic.
  </Accordion>
  
  <Accordion title="Cache-Aside with Write-Through">
    Combine cache-aside reads with write-through writes for optimal performance and consistency. This pattern reads from cache when possible (cache-aside) but writes to both cache and source simultaneously (write-through), ensuring consistency while maintaining performance.
    
    ```typescript
    class CacheAsideWriteThrough<T> {
      constructor(
        private store: IgniterStoreAdapter,
        private readFn: (id: string) => Promise<T | null>,
        private writeFn: (id: string, data: T) => Promise<T>,
        private ttl = 3600
      ) {}
      
      async read(id: string): Promise<T | null> {
        // Cache-aside: Check cache first
        const cached = await this.store.get<T>(`entity:${id}`);
        if (cached) {
          return cached;
        }
        
        // Fetch from source
        const entity = await this.readFn(id);
        if (!entity) {
          return null;
        }
        
        // Cache result
        await this.store.set(`entity:${id}`, entity, { ttl: this.ttl });
        
        return entity;
      }
      
      async write(id: string, data: T): Promise<T> {
        // Write-through: Write to both cache and source
        const [saved] = await Promise.all([
          this.writeFn(id, data),
          this.store.set(`entity:${id}`, data, { ttl: this.ttl }),
        ]);
        
        return saved;
      }
      
      async delete(id: string): Promise<void> {
        // Delete from both cache and source
        await Promise.all([
          this.readFn(id).then(entity => entity && this.writeFn(id, entity as any)),
          this.store.delete(`entity:${id}`),
        ]);
      }
    }
    ```
    
    Cache-aside with write-through combines the performance benefits of cache-aside reads with the consistency guarantees of write-through writes. This pattern optimizes both read and write performance while maintaining data consistency.
  </Accordion>
  
  <Accordion title="Event Sourcing with Cache">
    Use Pub/Sub for event sourcing combined with caching for fast event replay. This pattern stores events in cache while publishing them via Pub/Sub, enabling fast event replay and real-time event processing.
    
    ```typescript
    class EventStore {
      constructor(private store: IgniterStoreAdapter) {}
      
      async publishEvent(event: Event): Promise<void> {
        // Store event
        const eventKey = `event:${event.id}`;
        await this.store.set(eventKey, event, { ttl: 86400 * 7 }); // 7 days
        
        // Publish to channel
        await this.store.publish(`events:${event.type}`, event);
      }
      
      async subscribeToEvents(
        eventType: string,
        handler: (event: Event) => Promise<void>
      ): Promise<void> {
        await this.store.subscribe(`events:${eventType}`, handler);
      }
      
      async replayEvents(
        eventType: string,
        fromDate: Date
      ): Promise<Event[]> {
        // This is a simplified example
        // In production, you'd use a proper event store
        const events: Event[] = [];
        // Implementation depends on your event storage strategy
        return events;
      }
    }
    ```
    
    Event sourcing with cache enables fast event replay while maintaining real-time event processing. This pattern combines caching for event storage with Pub/Sub for event distribution.
  </Accordion>
</Accordions>

---

## Multi-Tenant Patterns

Multi-tenant applications require tenant isolation to ensure data separation between tenants. These patterns demonstrate how to implement tenant isolation using key prefixes and tenant-scoped channels, enabling secure multi-tenant applications that share the same Redis infrastructure.

Tenant isolation is critical for SaaS applications where multiple tenants share the same infrastructure. These patterns ensure data separation while maintaining performance and scalability.

<Accordions>
  <Accordion title="Tenant Isolation">
    Implement tenant isolation using key prefixes to ensure data separation between tenants. Tenant isolation prevents one tenant from accessing another tenant's data while sharing the same Redis infrastructure.
    
    ```typescript
    class TenantStore {
      constructor(
        private store: IgniterStoreAdapter,
        private tenantId: string
      ) {}
      
      private prefix(key: string): string {
        return `tenant:${this.tenantId}:${key}`;
      }
      
      async get<T>(key: string): Promise<T | null> {
        return this.store.get<T>(this.prefix(key));
      }
      
      async set(key: string, value: any, options?: { ttl?: number }): Promise<void> {
        return this.store.set(this.prefix(key), value, options);
      }
      
      async delete(key: string): Promise<void> {
        return this.store.delete(this.prefix(key));
      }
      
      async publish(channel: string, message: any): Promise<void> {
        // Tenant-scoped channels
        return this.store.publish(`tenant:${this.tenantId}:${channel}`, message);
      }
      
      async subscribe(channel: string, callback: EventCallback): Promise<void> {
        return this.store.subscribe(`tenant:${this.tenantId}:${channel}`, callback);
      }
    }

    // Usage
    const tenantStore = new TenantStore(igniter.store, request.tenantId);
    const data = await tenantStore.get('user:123');
    ```
    
    Tenant isolation ensures data separation between tenants while sharing Redis infrastructure. Key prefixes and tenant-scoped channels provide secure multi-tenant support.
  </Accordion>
</Accordions>

---

## Testing Strategies

Testing Store adapter usage requires strategies for mocking store operations, testing cache behavior, and verifying Pub/Sub functionality. These strategies help you write reliable tests that verify your Store usage works correctly without requiring a real Redis instance.

Good testing strategies ensure your Store usage works correctly and handles edge cases properly. They help you build reliable applications by catching issues early in the development process.

<Accordions>
  <Accordion title="Mock Store for Testing">
    Create a mock store for unit tests that implements the Store adapter interface. Mock stores allow you to test Store usage without requiring a real Redis instance, making tests faster and more reliable.
    
    ```typescript
    class MockStore implements IgniterStoreAdapter {
      private data = new Map<string, string>();
      private ttl = new Map<string, number>();
      
      async get<T>(key: string): Promise<T | null> {
        const value = this.data.get(key);
        if (!value) return null;
        
        // Check TTL
        const expiry = this.ttl.get(key);
        if (expiry && Date.now() > expiry) {
          this.data.delete(key);
          this.ttl.delete(key);
          return null;
        }
        
        return JSON.parse(value) as T;
      }
      
      async set(key: string, value: any, options?: { ttl?: number }): Promise<void> {
        this.data.set(key, JSON.stringify(value));
        
        if (options?.ttl) {
          this.ttl.set(key, Date.now() + options.ttl * 1000);
        }
      }
      
      async delete(key: string): Promise<void> {
        this.data.delete(key);
        this.ttl.delete(key);
      }
      
      async has(key: string): Promise<boolean> {
        return this.data.has(key);
      }
      
      async increment(key: string): Promise<number> {
        const current = (await this.get<number>(key)) || 0;
        const next = current + 1;
        await this.set(key, next);
        return next;
      }
      
      async expire(key: string, ttl: number): Promise<void> {
        this.ttl.set(key, Date.now() + ttl * 1000);
      }
      
      async publish(channel: string, message: any): Promise<void> {
        // Mock implementation
      }
      
      async subscribe(channel: string, callback: EventCallback): Promise<void> {
        // Mock implementation
      }
      
      async unsubscribe(channel: string, callback?: EventCallback): Promise<void> {
        // Mock implementation
      }
      
      get client() {
        return {} as any;
      }
    }
    ```
    
    Mock stores enable fast, reliable unit tests without requiring Redis. They implement the Store adapter interface, making it easy to test Store usage in isolation.
  </Accordion>
</Accordions>

---

## Production Best Practices

Following production best practices ensures your Store adapter usage is reliable, performant, and maintainable. These practices cover TTL management, performance monitoring, and graceful degradation. Applying these practices helps you build production-ready applications that handle failures gracefully and perform well under load.

Production best practices prevent common issues like inappropriate TTL values, poor cache performance, and failure cascades. They ensure your Store usage works correctly in production environments and scales effectively.

<Accordions>
  <Accordion title="Use Appropriate TTLs">
    Use TTL values that match your data's volatility and freshness requirements. Stable data like configuration can use longer TTLs, while volatile data like rate limits need shorter TTLs. Matching TTL to data characteristics ensures optimal performance and data freshness.
    
    ```typescript
    // ✅ Good: TTL matches data volatility
    await igniter.store.set('config:app', config, { ttl: 86400 }); // Stable data
    await igniter.store.set('user:session', session, { ttl: 3600 }); // Session data
    await igniter.store.set('api:rate', count, { ttl: 60 }); // Volatile data

    // ❌ Bad: Inappropriate TTLs
    await igniter.store.set('user:session', session, { ttl: 31536000 }); // Too long
    await igniter.store.set('config:app', config, { ttl: 60 }); // Too short
    ```
    
    Appropriate TTL values ensure data expires at the right time—not too soon (causing unnecessary re-fetching) and not too late (serving stale data). Match TTL values to your data's volatility and freshness requirements.
  </Accordion>
  
  <Accordion title="Monitor Cache Performance">
    Track cache hit/miss rates and latency to understand cache performance. Monitoring cache performance helps you optimize cache usage, identify bottlenecks, and ensure your caching strategy is working effectively.
    
    ```typescript
    // Track cache hit/miss rates
    const getWithTracking = async <T>(
      key: string,
      context: AppContext
    ): Promise<T | null> => {
      const start = Date.now();
      
      try {
        const value = await igniter.store.get<T>(key);
        const duration = Date.now() - start;
        
        // Log metrics
        context.logger.debug('Cache operation', {
          key,
          hit: value !== null,
          duration,
        });
        
        return value;
      } catch (error) {
        context.logger.error('Cache operation failed', { error, key });
        throw error;
      }
    };
    ```
    
    Monitoring cache performance helps you optimize cache usage and identify bottlenecks. Track hit rates, miss rates, latency, and error rates to ensure your caching strategy is working effectively.
  </Accordion>
  
  <Accordion title="Implement Graceful Degradation">
    Always have fallback strategies that allow your application to continue functioning when caching fails. Graceful degradation ensures your application remains functional even when Redis is temporarily unavailable.
    
    ```typescript
    // Always have a fallback
    const getCachedOrFetch = async <T>(
      key: string,
      fetchFn: () => Promise<T>,
      context: AppContext
    ): Promise<T> => {
      try {
        const cached = await igniter.store.get<T>(key);
        if (cached) return cached;
      } catch (error) {
        // Cache failed, but continue to source
        context.logger.warn('Cache read failed, using source', { error });
      }
      
      // Fetch from source
      const data = await fetchFn();
      
      // Try to cache, but don't fail if it doesn't work
      try {
        await igniter.store.set(key, data, { ttl: 3600 });
      } catch (error) {
        context.logger.warn('Cache write failed', { error });
      }
      
      return data;
    };
    ```
    
    Graceful degradation ensures your application continues functioning when caching fails. Always have fallback strategies that allow your application to degrade gracefully and continue serving users.
  </Accordion>
</Accordions>

---


